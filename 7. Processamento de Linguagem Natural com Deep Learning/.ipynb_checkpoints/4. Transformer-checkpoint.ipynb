{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ac689b",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fbb65",
   "metadata": {},
   "source": [
    "# Teoria\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbb26e",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "### RNNs clássicas para NLP\n",
    "\n",
    "- Palavras são codificadas em vetores\n",
    "- Cada novo estado é baseado no estado anterior\n",
    "- Decodificação começa no estado final do codificador\n",
    "![Rnns_classica](images/rnn_classica.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292cc5a",
   "metadata": {},
   "source": [
    "### Mecanismo de atenção\n",
    "\n",
    "- ultima camada do codificador sobrecarregada com todos os textos\n",
    "- atenção maior para as camadas\n",
    "- maiores pesos para o contexto estado anterior\n",
    "\n",
    "![Mecanismo de atenção](images/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762d943",
   "metadata": {},
   "source": [
    "## Arquitetura \n",
    "\n",
    "Essa arquitetura tem como foco os mecanismos de atenção. Ao em vez de cada palavra receber a atenção, nos Transformers cada frase terá esse processo.\n",
    "\n",
    "![arquitetura](images/transformer.png)\n",
    "![arquitetura](images/self-attention.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8c9ee",
   "metadata": {},
   "source": [
    "## Scale-dot product\n",
    "\n",
    "**Ideia principal:**\n",
    "- 2 sequências (iguais no caso de self-attention), A e B\n",
    "- calcular como cada elemento de A está relacionado a cada elmento de B\n",
    "- depois recombinamos A de acordo com essa relação\n",
    "\n",
    "**Matematicamente**, dot-product indica a similaridade entre dois vetores.\n",
    "\n",
    "![scale_dot-product](images/scale_dot-product.png)\n",
    "\n",
    "![scale_dot-product](images/scale_dot-product2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7eaaed",
   "metadata": {},
   "source": [
    "## Look-ahead Mask\n",
    "\n",
    "![look-ahead](images/look-ahead.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5819d",
   "metadata": {},
   "source": [
    "## Attention Layer\n",
    "\n",
    "![attentio layer](images/attention-layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95aed6",
   "metadata": {},
   "source": [
    "## Multi-head attention Layer\n",
    "\n",
    "![multi-head](images/multi-head.png)\n",
    "\n",
    "## Positional Encoding\n",
    "\n",
    "![positional-encod](images/positional-encod.png)\n",
    "\n",
    "## Feed-forward layers (camadas densas)\n",
    "\n",
    "- composta de 2 transformações lineares\n",
    "\n",
    "$$\n",
    "FFN(x) = \\max(0, x W_1 + b_1)W_2 + b_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4b39f",
   "metadata": {},
   "source": [
    "## Residual connections:\n",
    "\n",
    "- **Add & Norm:** não esquecer a informação da etapa anterior, ajudando a aprendizagem durante o *backpropagation*.\n",
    "- **Last linear:** a saída do decodificador passa por uma camada densa de acordo com o tamanho do vocabulário e com a aplicação da função softmax, gerando probabilidades para cada palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff205013",
   "metadata": {},
   "source": [
    "# Prática\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668911a",
   "metadata": {},
   "source": [
    "## Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f3bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841997a",
   "metadata": {},
   "source": [
    "- Bases de dados: https://www.statmt.org/europarl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75112094",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../_IAExpert_private/7. Processamento de Linguagem Natural com Deep LEarning/pt-en'\n",
    "\n",
    "with open(f\"{file_path}/europarl-v7.pt-en.en\", mode='r', encoding='utf-8') as f:\n",
    "    europarl_en = f.read()\n",
    "\n",
    "with open(f\"{file_path}/europarl-v7.pt-en.pt\", mode='r', encoding='utf-8') as f:\n",
    "    europarl_pt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bed9681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resumption of the session\\nI declare resumed the session of the European Parliament adjourned on Frid'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl_en[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae0ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960408, 1960408)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = europarl_en.split('\\n')\n",
    "pt = europarl_pt.split('\\n')\n",
    "\n",
    "len(en), len(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da63152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Another positive sign is the imminent creation of the Euro-Mediterranean Forum which is nothing other than the completion of the Barcelona declaration itself.',\n",
       " 'Outro sinal positivo é constituído pelo nascimento iminente do Fórum Euro-Mediterrânico, que outra coisa não é senão a conclusão da própria declaração de Barcelona.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(en)-1)\n",
    "en[i], pt[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4520058",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3972171",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = europarl_en\n",
    "corpus_en = re.sub(r\"\\.(?=[0-9][a-z][A-Z])\", '.$$$', corpus_en)\n",
    "corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
    "corpus_en = re.sub(r\" +\", ' ', corpus_en)\n",
    "corpus_en = corpus_en.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pt = europarl_pt\n",
    "corpus_pt = re.sub(r\"\\.(?=[0-9][a-z][A-Z])\", '.$$$', corpus_pt)\n",
    "corpus_pt = re.sub(r\".\\$\\$\\$\", '', corpus_pt)\n",
    "corpus_pt = re.sub(r\" +\", ' ', corpus_pt)\n",
    "corpus_pt = corpus_pt.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65025476",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
