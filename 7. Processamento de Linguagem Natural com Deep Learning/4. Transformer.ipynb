{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ac689b",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c50a88",
   "metadata": {},
   "source": [
    "Referência: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fbb65",
   "metadata": {},
   "source": [
    "# Teoria\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbb26e",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "### RNNs clássicas para NLP\n",
    "\n",
    "- Palavras são codificadas em vetores\n",
    "- Cada novo estado é baseado no estado anterior\n",
    "- Decodificação começa no estado final do codificador\n",
    "![Rnns_classica](images/rnn_classica.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292cc5a",
   "metadata": {},
   "source": [
    "### Mecanismo de atenção\n",
    "\n",
    "- ultima camada do codificador sobrecarregada com todos os textos\n",
    "- atenção maior para as camadas\n",
    "- maiores pesos para o contexto estado anterior\n",
    "\n",
    "![Mecanismo de atenção](images/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762d943",
   "metadata": {},
   "source": [
    "## Arquitetura \n",
    "\n",
    "Essa arquitetura tem como foco os mecanismos de atenção. Ao em vez de cada palavra receber a atenção, nos Transformers cada frase terá esse processo.\n",
    "\n",
    "![arquitetura](images/transformer.png)\n",
    "![arquitetura](images/self-attention.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8c9ee",
   "metadata": {},
   "source": [
    "## Scale-dot product\n",
    "\n",
    "**Ideia principal:**\n",
    "- 2 sequências (iguais no caso de self-attention), A e B\n",
    "- calcular como cada elemento de A está relacionado a cada elmento de B\n",
    "- depois recombinamos A de acordo com essa relação\n",
    "\n",
    "**Matematicamente**, dot-product indica a similaridade entre dois vetores.\n",
    "\n",
    "![scale_dot-product](images/scale_dot-product.png)\n",
    "\n",
    "![scale_dot-product](images/scale_dot-product2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7eaaed",
   "metadata": {},
   "source": [
    "## Look-ahead Mask\n",
    "\n",
    "![look-ahead](images/look-ahead.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5819d",
   "metadata": {},
   "source": [
    "## Attention Layer\n",
    "\n",
    "![attentio layer](images/attention-layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95aed6",
   "metadata": {},
   "source": [
    "## Multi-head attention Layer\n",
    "\n",
    "![multi-head](images/multi-head.png)\n",
    "\n",
    "## Positional Encoding\n",
    "\n",
    "![positional-encod](images/positional-encod.png)\n",
    "\n",
    "## Feed-forward layers (camadas densas)\n",
    "\n",
    "- composta de 2 transformações lineares\n",
    "\n",
    "$$\n",
    "FFN(x) = \\max(0, x W_1 + b_1)W_2 + b_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4b39f",
   "metadata": {},
   "source": [
    "## Residual connections:\n",
    "\n",
    "- **Add & Norm:** não esquecer a informação da etapa anterior, ajudando a aprendizagem durante o *backpropagation*.\n",
    "- **Last linear:** a saída do decodificador passa por uma camada densa de acordo com o tamanho do vocabulário e com a aplicação da função softmax, gerando probabilidades para cada palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff205013",
   "metadata": {},
   "source": [
    "# Prática\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668911a",
   "metadata": {},
   "source": [
    "## Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f3bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841997a",
   "metadata": {},
   "source": [
    "- Bases de dados: https://www.statmt.org/europarl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75112094",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../_IAExpert_private/7. Processamento de Linguagem Natural com Deep LEarning/pt-en'\n",
    "\n",
    "with open(f\"{file_path}/europarl-v7.pt-en.en\", mode='r', encoding='utf-8') as f:\n",
    "    europarl_en = f.read()\n",
    "\n",
    "with open(f\"{file_path}/europarl-v7.pt-en.pt\", mode='r', encoding='utf-8') as f:\n",
    "    europarl_pt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bed9681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resumption of the session\\nI declare resumed the session of the European Parliament adjourned on Frid'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl_en[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae0ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960408, 1960408)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = europarl_en.split('\\n')\n",
    "pt = europarl_pt.split('\\n')\n",
    "\n",
    "len(en), len(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da63152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Since the South Korean Constitutional Court itself recognised that the death penalty could be subject to errors and abuse, our concerns brought forward today might strengthen the democratic institutions of the Republic of Korea in the idea that this method of punishment should be abolished for good.',\n",
       " 'Uma vez que o próprio Tribunal Constitucional sul-coreano reconheceu que a pena de morte pode estar sujeita a erros e abusos, as nossas preocupações hoje aqui expostas poderão ajudar a reforçar nas instituições democráticas da República da Coreia a ideia de que esse método de punição deve ser abolido de uma vez por todas.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(en)-1)\n",
    "en[i], pt[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4520058",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b2b3a",
   "metadata": {},
   "source": [
    "```python\n",
    "corpus_en = europarl_en\n",
    "corpus_en = re.sub(r\"\\.(?=[0-9][a-z][A-Z])\", '.$$$', corpus_en)\n",
    "corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
    "corpus_en = re.sub(r\" +\", ' ', corpus_en)\n",
    "corpus_en = corpus_en.split('\\n')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e0543",
   "metadata": {},
   "source": [
    "```python\n",
    "corpus_pt = europarl_pt\n",
    "corpus_pt = re.sub(r\"\\.(?=[0-9][a-z][A-Z])\", '.$$$', corpus_pt)\n",
    "corpus_pt = re.sub(r\".\\$\\$\\$\", '', corpus_pt)\n",
    "corpus_pt = re.sub(r\" +\", ' ', corpus_pt)\n",
    "corpus_pt = corpus_pt.split('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52278de7",
   "metadata": {},
   "source": [
    "```python\n",
    "with open(\"corpus.pkl\", \"wb\") as f:\n",
    "    pickle.dump([corpus_en, corpus_pt], f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeaf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"corpus.pkl\", 'rb') as f:\n",
    "    corpus_en, corpus_pt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7f706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960408, 1960408)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_en), len(corpus_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9b616",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "- texto para número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0922c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_en, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3ed0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_pt, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979239be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8188, 8116)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.vocab_size, tokenizer_pt.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a958e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_en = tokenizer_en.vocab_size + 2\n",
    "vocab_size_pt = tokenizer_pt.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5da964",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[vocab_size_en - 2] + tokenizer_en.encode(sentence) + [vocab_size_en - 1] for sentence in corpus_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1634c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [[vocab_size_pt - 2] + tokenizer_pt.encode(sentence) + [vocab_size_pt - 1] for sentence in corpus_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a87c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8188, 2456, 972, 2106, 3, 1, 2569, 8189]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b10ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8116, 834, 705, 7, 3561, 8117]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91819139",
   "metadata": {},
   "source": [
    "### Remoção de sentenças muito longas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3149e67",
   "metadata": {},
   "source": [
    "#### A partir dos inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00b7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 15\n",
    "idx_to_remove = [count for count, sent in enumerate(inputs) if len(sent) > max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56e9041b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1686352"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e6bd2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e18d8",
   "metadata": {},
   "source": [
    "#### A partir dos outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7861423",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 15\n",
    "idx_to_remove = [count for count, sent in enumerate(outputs) if len(sent) > max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d07d99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ce0977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "538a9017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208142, 208142)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs), len(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3fc40",
   "metadata": {},
   "source": [
    "### Paddings e batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "980f63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, value=0, padding='post', maxlen=max_length)\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs, value=0, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa19e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19689 15 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([8188, 7972,   25,  265, 4587,    1,  182,  297, 7049, 7973, 8189,\n",
       "           0,    0,    0,    0]),\n",
       " array([8116, 7900,   36,  150, 1460, 7892, 3144,    3,  237,  645, 7901,\n",
       "        8117,    0,    0,    0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(inputs))\n",
    "print(i, len(inputs[i]), len(outputs[i]))\n",
    "inputs[i], outputs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc4666b",
   "metadata": {},
   "source": [
    "Vamos mudar para o formato do tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "746b231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fd19e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 15), (None, 15)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2794d4",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd373bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angles = 1 / np.power(10000., (2*(i // 2)) / np.float32(d_model))\n",
    "        return pos * angles\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        seq_length = input.shape.as_list()[-2]\n",
    "        d_model = input.shape.as_list()[-1]\n",
    "        angles = self.get_angles(np.range(seq_length)[:, np.newaxis], \n",
    "                                 np.arange(d_model)[np.newaxis,:], \n",
    "                                 d_model)\n",
    "        \n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "        pos_encoding = angles[np.newaxis, ...]\n",
    "        \n",
    "        return inputs + tf.cast(post_encoding, tf.float32)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02146dbc",
   "metadata": {},
   "source": [
    "## Mecanismo de atenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4f0e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_product += (mask * -1e9)\n",
    "        \n",
    "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeatAttention(layers.Layer):\n",
    "    \n",
    "    def __init__(self, nb_proj):\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "    def split_proj(self, inputs, batch_size):\n",
    "        \n",
    "    def call(self, queries, keys, values, mask):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
