{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ac689b",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fbb65",
   "metadata": {},
   "source": [
    "# Teoria\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbb26e",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "### RNNs clássicas para NLP\n",
    "\n",
    "- Palavras são codificadas em vetores\n",
    "- Cada novo estado é baseado no estado anterior\n",
    "- Decodificação começa no estado final do codificador\n",
    "![Rnns_classica](images/rnn_classica.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292cc5a",
   "metadata": {},
   "source": [
    "### Mecanismo de atenção\n",
    "\n",
    "- ultima camada do codificador sobrecarregada com todos os textos\n",
    "- atenção maior para as camadas\n",
    "- maiores pesos para o contexto estado anterior\n",
    "\n",
    "![Mecanismo de atenção](images/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762d943",
   "metadata": {},
   "source": [
    "## Arquitetura \n",
    "\n",
    "Essa arquitetura tem como foco os mecanismos de atenção. Ao em vez de cada palavra receber a atenção, nos Transformers cada frase terá esse processo.\n",
    "\n",
    "![arquitetura](images/transformer.png)\n",
    "![arquitetura](images/self-attention.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8c9ee",
   "metadata": {},
   "source": [
    "## Scale-dot product\n",
    "\n",
    "**Ideia principal:**\n",
    "- 2 sequências (iguais no caso de self-attention), A e B\n",
    "- calcular como cada elemento de A está relacionado a cada elmento de B\n",
    "- depois recombinamos A de acordo com essa relação\n",
    "\n",
    "**Matematicamente**, dot-product indica a similaridade entre dois vetores.\n",
    "\n",
    "![scale_dot-product](images/scale_dot-product.png)\n",
    "\n",
    "![scale_dot-product](images/scale_dot-product2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7eaaed",
   "metadata": {},
   "source": [
    "## Look-ahead Mask\n",
    "\n",
    "![look-ahead](images/look-ahead.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5819d",
   "metadata": {},
   "source": [
    "## Attention Layer\n",
    "\n",
    "![attentio layer](images/attention-layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95aed6",
   "metadata": {},
   "source": [
    "## Multi-head attention Layer\n",
    "\n",
    "![multi-head](images/multi-head.png)\n",
    "\n",
    "## Positional Encoding\n",
    "\n",
    "![positional-encod](images/positional-encod.png)\n",
    "\n",
    "## Feed-forward layers (camadas densas)\n",
    "\n",
    "- composta de 2 transformações lineares\n",
    "\n",
    "$$\n",
    "FFN(x) = \\max(0, x W_1 + b_1)W_2 + b_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4b39f",
   "metadata": {},
   "source": [
    "## Residual connections:\n",
    "\n",
    "- **Add & Norm:** não esquecer a informação da etapa anterior, ajudando a aprendizagem durante o *backpropagation*.\n",
    "- **Last linear:** a saída do decodificador passa por uma camada densa de acordo com o tamanho do vocabulário e com a aplicação da função softmax, gerando probabilidades para cada palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff205013",
   "metadata": {},
   "source": [
    "# Prática\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668911a",
   "metadata": {},
   "source": [
    "## Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f3bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841997a",
   "metadata": {},
   "source": [
    "- Bases de dados: https://www.statmt.org/europarl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75112094",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../_IAExpert_private/7. Processamento de Linguagem Natural com Deep LEarning/pt-en'\n",
    "\n",
    "with open(f\"{file_path}/europarl-v7.pt-en.en\", mode='r', encoding='utf-8') as f:\n",
    "    europarl_en = f.read()\n",
    "\n",
    "with open(f\"{file_path}/europarl-v7.pt-en.pt\", mode='r', encoding='utf-8') as f:\n",
    "    europarl_pt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bed9681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resumption of the session\\nI declare resumed the session of the European Parliament adjourned on Frid'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl_en[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae0ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960408, 1960408)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = europarl_en.split('\\n')\n",
    "pt = europarl_pt.split('\\n')\n",
    "\n",
    "len(en), len(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da63152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('For this reason, and with reservations as above, I have voted against the report.',\n",
       " 'Por tal motivo, e pelas reservas supramencionadas, votei contra o relatório.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(en)-1)\n",
    "en[i], pt[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4520058",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b2b3a",
   "metadata": {},
   "source": [
    "```python\n",
    "corpus_en = europarl_en\n",
    "corpus_en = re.sub(r\"\\.(?=[0-9][a-z][A-Z])\", '.$$$', corpus_en)\n",
    "corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
    "corpus_en = re.sub(r\" +\", ' ', corpus_en)\n",
    "corpus_en = corpus_en.split('\\n')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e0543",
   "metadata": {},
   "source": [
    "```python\n",
    "corpus_pt = europarl_pt\n",
    "corpus_pt = re.sub(r\"\\.(?=[0-9][a-z][A-Z])\", '.$$$', corpus_pt)\n",
    "corpus_pt = re.sub(r\".\\$\\$\\$\", '', corpus_pt)\n",
    "corpus_pt = re.sub(r\" +\", ' ', corpus_pt)\n",
    "corpus_pt = corpus_pt.split('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52278de7",
   "metadata": {},
   "source": [
    "```python\n",
    "with open(\"corpus.pkl\", \"wb\") as f:\n",
    "    pickle.dump([corpus_en, corpus_pt], f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaeaf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"corpus.pkl\", 'rb') as f:\n",
    "    corpus_en, corpus_pt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7f706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960408, 1960408)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_en), len(corpus_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9b616",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "- texto para número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0922c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_en, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af3ed0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_pt, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "979239be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8188, 8116)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.vocab_size, tokenizer_pt.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a958e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_en = tokenizer_en.vocab_size + 2\n",
    "vocab_size_pt = tokenizer_pt.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5da964",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_en = [[vocab_size_en - 2] + tokenizer_en.encode(sentence) + [vocab_size_en - 1] for sentence in corpus_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1634c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_pt = [[vocab_size_pt - 2] + tokenizer_pt.encode(sentence) + [vocab_size_pt - 1] for sentence in corpus_pt]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
